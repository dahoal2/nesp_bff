{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0218cddb-e298-498d-9c87-a5d5d3b7532f",
   "metadata": {},
   "source": [
    "# QDC scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850d7b5e-fb1c-4a5e-9eb9-de660b1fad8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T07:15:49.869078Z",
     "iopub.status.busy": "2025-07-21T07:15:49.868832Z",
     "iopub.status.idle": "2025-07-21T07:16:09.052185Z",
     "shell.execute_reply": "2025-07-21T07:16:09.051045Z",
     "shell.execute_reply.started": "2025-07-21T07:15:49.869051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xclim/sdba.py:12: UserWarning: The `xclim.sdba` module has been split into its own package `xsdba`. Users are encouraged to use `xsdba` directly. For the time being, `xclim.sdba` will import `xsdba` to allow for API compatibility. This behaviour may change in the future. For more information, see: https://xsdba.readthedocs.io/en/stable/xclim_migration_guide.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "from xclim import sdba\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import utils\n",
    "sys.path.append('/home/565/dh4185/mn51-dh4185/repos_collab/nesp_bff/')\n",
    "import utils\n",
    "\n",
    "# Static metadata dictionaries\n",
    "from utils import locations, model_dict, vars_1hr, vars_day, cmap_dict\n",
    "\n",
    "# sys.path.append('/home/565/dh4185/mn51-dh4185/repos_collab/nesp_bff/xsdba')\n",
    "# import xsdba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c859f682-6540-41e5-b5c2-4567f8e30c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T07:16:09.053972Z",
     "iopub.status.busy": "2025-07-21T07:16:09.053593Z",
     "iopub.status.idle": "2025-07-21T07:16:09.057806Z",
     "shell.execute_reply": "2025-07-21T07:16:09.056949Z",
     "shell.execute_reply.started": "2025-07-21T07:16:09.053951Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! python -m pip install xsdba\n",
    "# import xsdba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f4f3b3-025d-45e2-a6c5-062a532e7ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T07:16:09.058586Z",
     "iopub.status.busy": "2025-07-21T07:16:09.058406Z",
     "iopub.status.idle": "2025-07-21T07:16:09.070220Z",
     "shell.execute_reply": "2025-07-21T07:16:09.069265Z",
     "shell.execute_reply.started": "2025-07-21T07:16:09.058569Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Settings\n",
    "\n",
    "# Narrow down SSP, RCM and start/end year\n",
    "_scenario = \"ssp370\" #\"ssp370\" ssp126 historical\n",
    "_rcm = \"CCAM-v2203-SN\" #\"BARPA-R\" #CCAM-v2203-SN\"\n",
    "# _gcm = \"ACCESS-ESM1-5\"\n",
    "_location = \"Melbourne\"\n",
    "_future = \"2050\"\n",
    "\n",
    "# Directories\n",
    "root_dir = \"/g/data/eg3/nesp_bff/\"\n",
    "plot_dir = \"/g/data/eg3/nesp_bff/plots/qdc_adjustfactor/\"\n",
    "\n",
    "if _rcm == \"CCAM-v2203-SN\":\n",
    "    in_dir = f\"{root_dir}step1_raw_data_extraction/CSIRO-CCAM/\"\n",
    "    out_dir = f\"{root_dir}step2_qdc_scaling/CSIRO-CCAM/\"\n",
    "else:\n",
    "    in_dir = f\"{root_dir}step1_raw_data_extraction/{_rcm}/\"\n",
    "    out_dir = f\"{root_dir}step2_qdc_scaling/{_rcm}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c2518-06a1-4207-a87a-d7fcd1ec9e3b",
   "metadata": {},
   "source": [
    "### QDC daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a121b0-a4d4-4819-a251-d40c8543c357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vars_daily = [\"tasmax\",\"tasmin\",\"hussmax\",\"hussmin\",\"psl\",\"sfcWind\",\"sfcWindmax\",\"rsds\",\"rsdsdir\"]\n",
    "\n",
    "print(f\"---------- {_rcm} for daily data ----------\")\n",
    "\n",
    "for loc in locations:\n",
    "    print(f\"========================== {loc} =======================\")\n",
    "    ds_ref = xr.open_dataset(f\"{root_dir}step1_raw_data_extraction/BARRA-R2/{loc}_AUS-11_ERA5_historical_hres_BOM_BARRA-R2_v1_day_1985-2014.nc\").load()\n",
    "\n",
    "    for _gcm in model_dict[_rcm][\"gcms\"]:\n",
    "        print(f\"***** {_gcm} *****\")\n",
    "\n",
    "        out_file = (\n",
    "            f\"{out_dir}{loc}_\"\n",
    "            f\"{model_dict[_rcm]['grid']}_\"\n",
    "            f\"{_gcm}_{_scenario}_\"\n",
    "            f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "            f\"{model_dict[_rcm]['org']}_\"\n",
    "            f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "            f\"day_{_future}_QDC-BARRAR2.nc\"\n",
    "        )\n",
    "        fig_file = plot_dir+out_file.replace(\".nc\",\"_AdjFact_facetplot.pdf\").split('/')[-1]\n",
    "\n",
    "        if not os.path.exists(out_file):\n",
    "            print(f\"Processing: {out_file}.....\")\n",
    "            model_historical_file = (\n",
    "                f\"{in_dir}{loc}_\"\n",
    "                f\"{model_dict[_rcm]['grid']}_\"\n",
    "                f\"{_gcm}_historical_\"\n",
    "                f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "                f\"{model_dict[_rcm]['org']}_\"\n",
    "                f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "                f\"day_1985-2014.nc\"\n",
    "            )\n",
    "            model_future_file = (\n",
    "                f\"{in_dir}{loc}_\"\n",
    "                f\"{model_dict[_rcm]['grid']}_\"\n",
    "                f\"{_gcm}_{_scenario}_\"\n",
    "                f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "                f\"{model_dict[_rcm]['org']}_\"\n",
    "                f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "                f\"day_2035-2064.nc\"\n",
    "            )\n",
    "            ds_model_historical = xr.open_dataset(model_historical_file).load()\n",
    "            ds_model_future = xr.open_dataset(model_future_file).load()\n",
    "\n",
    "            ds_model_historical[\"lat\"] = ds_ref[\"lat\"]\n",
    "            ds_model_historical[\"lon\"] = ds_ref[\"lon\"]\n",
    "            ds_model_future[\"lat\"] = ds_ref[\"lat\"]\n",
    "            ds_model_future[\"lon\"] = ds_ref[\"lon\"]\n",
    "            ds_model_future_aligned = utils.align_future_to_historical(ds_model_historical, ds_model_future)\n",
    "\n",
    "            facet_data = []\n",
    "            var_list = []\n",
    "\n",
    "            for _var in vars_daily:\n",
    "                print(f\"===== Var: {_var} =====\")\n",
    "\n",
    "                da_ref = ds_ref[_var]\n",
    "                da_model_historical = ds_model_historical[_var]\n",
    "                da_model_future = ds_model_future_aligned[_var]\n",
    "\n",
    "                _kind = '+' if _var in [\"tasmax\", \"tasmin\"] else '*'\n",
    "\n",
    "                QDC = sdba.QuantileDeltaMapping.train(\n",
    "                    da_model_future,\n",
    "                    da_model_historical,\n",
    "                    nquantiles=100,\n",
    "                    group='time.month',\n",
    "                    kind=_kind\n",
    "                )\n",
    "\n",
    "                da_ref_adjust = QDC.adjust(da_ref, interp='linear').rename(_var)\n",
    "                var_list.append(da_ref_adjust.to_dataset())\n",
    "\n",
    "                if not os.path.exists(fig_file):\n",
    "                    def plot_mean(ax, var=_var, da_ref=da_ref, da_model_historical=da_model_historical, da_model_future=da_model_future, da_ref_adjust=da_ref_adjust):\n",
    "                        da_ref.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=\"Reference historical (BARRA-R2, 2000)\")\n",
    "                        da_model_historical.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=f\"{_rcm}-{_gcm} historical (2000)\")\n",
    "                        da_model_future.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=f\"{_rcm}-{_gcm} {_scenario} - future ({_future})\")\n",
    "                        da_ref_adjust.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=\"Reference - adjusted - future\", linestyle=\"--\")\n",
    "                        ax.set_title(f\"{loc}, {var} - Mean Daily\")\n",
    "                        ax.legend()\n",
    "    \n",
    "                    facet_data.append(plot_mean)\n",
    "    \n",
    "                    def plot_qdc_af(ax, var=_var, qdc=QDC, kind=_kind, cmap_default=cmap_dict.get(_var, \"viridis\")):\n",
    "                        af = qdc.ds.af\n",
    "                        vmin = float(af.min())\n",
    "                        vmax = float(af.max())\n",
    "    \n",
    "                        if vmin < 0 and vmax > 0:\n",
    "                            cmap = \"RdBu_r\"\n",
    "                            center = 0.0\n",
    "                        else:\n",
    "                            cmap = cmap_default\n",
    "                            center = None\n",
    "    \n",
    "                        af.transpose(\"month\", \"quantiles\").plot.pcolormesh(\n",
    "                            ax=ax, cmap=cmap, center=center,\n",
    "                            x=\"quantiles\", y=\"month\",\n",
    "                            cbar_kwargs={\"label\": \"Adjustment Factor\"})\n",
    "                        ax.set_title(f\"{var} - Adjustment Factors ({kind})\")\n",
    "    \n",
    "                    facet_data.append(plot_qdc_af)\n",
    "    \n",
    "                    def plot_hist(ax, var=_var, da_ref=da_ref, da_model_historical=da_model_historical, da_model_future=da_model_future, da_ref_adjust=da_ref_adjust):\n",
    "                        sns.histplot(da_ref.values.flatten(), ax=ax, label=\"Obs (BARRA-R2)\", kde=True, stat=\"density\", bins=50, color=\"blue\")\n",
    "                        sns.histplot(da_model_historical.values.flatten(), ax=ax, label=f\"Hist {_rcm}-{_gcm} {_scenario}\", kde=True, stat=\"density\", bins=50, color=\"green\")\n",
    "                        sns.histplot(da_model_future.values.flatten(), ax=ax, label=f\"2050 {_rcm}-{_gcm} {_scenario}\", kde=True, stat=\"density\", bins=50, color=\"red\")\n",
    "                        sns.histplot(da_ref_adjust.values.flatten(), ax=ax, label=\"Adjusted\", kde=True, stat=\"density\", bins=50, color=\"purple\")\n",
    "                        ax.set_title(f\"{loc}, {var} - Distribution\")\n",
    "                        ax.legend()\n",
    "    \n",
    "                    facet_data.append(plot_hist)\n",
    "\n",
    "            da_var = xr.merge(var_list)\n",
    "            print(da_var)\n",
    "            da_var.to_netcdf(out_file)\n",
    "\n",
    "            if not os.path.exists(fig_file):\n",
    "                fig, axes = plt.subplots(9, 3, figsize=(30, 45))\n",
    "                axes = axes.flatten()\n",
    "    \n",
    "                for ax, plot_func in zip(axes, facet_data):\n",
    "                    plot_func(ax)\n",
    "    \n",
    "                plt.tight_layout()\n",
    "                fig.savefig(fig_file, bbox_inches='tight')\n",
    "                # plt.show()\n",
    "                plt.close()\n",
    "\n",
    "        else:\n",
    "            print(f'File for {loc} exists in output directory.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee02ffe-0425-4826-b9ad-b45030355e40",
   "metadata": {},
   "source": [
    "## QDC hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9fe09-cc0e-46a5-8ac5-38801ffb07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_1hr = ['tas','hurs','huss','sfcWind','psl','uas','vas','clt','rsds','rsdsdir']\n",
    "\n",
    "print(f\"---------- {_rcm} for hourly data ----------\")\n",
    "issue_list = []\n",
    "\n",
    "for loc in locations:\n",
    "    print(f\"========================== {loc} =======================\")\n",
    "    ds_ref = xr.open_dataset(f\"{root_dir}step1_raw_data_extraction/BARRA-R2/{loc}_AUS-11_ERA5_historical_hres_BOM_BARRA-R2_v1_1hr_1985-2014.nc\").load()\n",
    "\n",
    "    for _gcm in model_dict[_rcm][\"gcms\"]:\n",
    "        print(f\"***** {_gcm} *****\")\n",
    "\n",
    "        out_file = (\n",
    "            f\"{out_dir}{loc}_\"\n",
    "            f\"{model_dict[_rcm]['grid']}_\"\n",
    "            f\"{_gcm}_{_scenario}_\"\n",
    "            f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "            f\"{model_dict[_rcm]['org']}_\"\n",
    "            f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "            f\"1hr_{_future}_QDC-BARRAR2.nc\"\n",
    "        )\n",
    "        # fig_file = plot_dir+out_file.replace(\".nc\",\"_AdjFact_facetplot.pdf\").split('/')[-1]\n",
    "        try:\n",
    "            if not os.path.exists(out_file):\n",
    "                print(f\"Processing: {out_file}.....\")\n",
    "                model_historical_file = (\n",
    "                    f\"{in_dir}{loc}_\"\n",
    "                    f\"{model_dict[_rcm]['grid']}_\"\n",
    "                    f\"{_gcm}_historical_\"\n",
    "                    f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "                    f\"{model_dict[_rcm]['org']}_\"\n",
    "                    f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "                    f\"1hr_1985-2014.nc\"\n",
    "                )\n",
    "                model_future_file = (\n",
    "                    f\"{in_dir}{loc}_\"\n",
    "                    f\"{model_dict[_rcm]['grid']}_\"\n",
    "                    f\"{_gcm}_{_scenario}_\"\n",
    "                    f\"{model_dict[_rcm]['gcms'][_gcm]['mdl_run']}_\"\n",
    "                    f\"{model_dict[_rcm]['org']}_\"\n",
    "                    f\"{_rcm}_{model_dict[_rcm]['gcms'][_gcm]['version']}_\"\n",
    "                    f\"1hr_2035-2064.nc\"\n",
    "                )\n",
    "                ds_model_historical_1hr = xr.open_dataset(model_historical_file).load()\n",
    "                ds_model_future_1hr = xr.open_dataset(model_future_file).load()\n",
    "    \n",
    "                ds_model_historical_1hr[\"lat\"] = ds_ref[\"lat\"]\n",
    "                ds_model_historical_1hr[\"lon\"] = ds_ref[\"lon\"]\n",
    "                ds_model_future_1hr[\"lat\"] = ds_ref[\"lat\"]\n",
    "                ds_model_future_1hr[\"lon\"] = ds_ref[\"lon\"]\n",
    "                ds_model_future_1hr_aligned = utils.align_future_to_historical(ds_model_historical_1hr, ds_model_future_1hr)\n",
    "    \n",
    "                facet_data = []\n",
    "                var_list_1hr = []\n",
    "    \n",
    "                for _var in vars_1hr:\n",
    "                    print(f\"===== Var: {_var} =====\")\n",
    "    \n",
    "                    da_obs_1hr = ds_ref[_var]\n",
    "                    da_model_hist_1hr = ds_model_historical_1hr[_var]\n",
    "                    da_model_fut_1hr = ds_model_future_1hr_aligned[_var]\n",
    "    \n",
    "                    _kind = '+' if _var in [\"tas\",\"hurs\", \"clt\", \"uas\", \"vas\"] else '*'\n",
    "                                    \n",
    "                    da_adjusted_1hr, QDC_dict_1hr, adjusted_slices_1hr = utils.apply_hourly_qdc_sliding_window(\n",
    "                        da_obs=da_obs_1hr,\n",
    "                        da_model_historical=da_model_hist_1hr,\n",
    "                        da_model_future=da_model_fut_1hr,\n",
    "                        var=_var,\n",
    "                        kind=_kind,\n",
    "                        window=1\n",
    "                    )\n",
    "                    \n",
    "                    var_list_1hr.append(da_adjusted_1hr.rename(_var).to_dataset())\n",
    "    \n",
    "                    fig_file = plot_dir+(out_file.replace(\".nc\",f\"_AdjFact_facetplot_{_var}.pdf\").split('/')[-1])\n",
    "                    if _var in [\"rsds\",\"rsdsdir\"]:\n",
    "                        if not os.path.exists(fig_file):\n",
    "                            plot_diagnostics = utils.plot_qdc_hourly_diagnostics(da_obs_1hr,da_model_hist_1hr,\n",
    "                                                                                 da_model_fut_1hr,QDC_dict_1hr,\n",
    "                                                                                 adjusted_slices_1hr,_var,\n",
    "                                                                                 f\"{_rcm}-{_gcm}\",loc)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(fig_file, bbox_inches='tight')\n",
    "                            # plt.show()\n",
    "                            plt.close()\n",
    "                        \n",
    "                da_var_1hr = xr.merge(var_list_1hr)\n",
    "                print(da_var_1hr)\n",
    "                da_var_1hr.to_netcdf(out_file)\n",
    "            else:\n",
    "                print(f'File for {loc} exists in output directory.')\n",
    "                \n",
    "        except Exception as e:\n",
    "            issue_list.append(f\"Issue with {_var} in {_gcm} for {loc}. File not created: {out_file}. Error:{e}\")\n",
    "            print(f\"Issue with {_var} in {_gcm}. Not creating {out_file}. Skipping to next. Error:{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e42a24-c36f-4c32-9556-960b3db43d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in issue_list:\n",
    "    print(\"Summary of issues and files not created because of it: \\n\",item,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f0d4a-b621-48d8-871a-a91ddc9d524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars_1hr = ['rsds','rsdsdir']\n",
    "\n",
    "# in_dir = \"/g/data/eg3/nesp_bff/step1_raw_data_extraction/BARPA-R/\"\n",
    "# root_dir = \"/g/data/eg3/nesp_bff/\"\n",
    "\n",
    "# ds_model_future_1hr = xr.open_dataset(f\"{in_dir}Cairns_AUS-15_CMCC-ESM2_ssp370_r1i1p1f1_BOM_BARPA-R_v1-r1_1hr_2035-2064.nc\").load()\n",
    "# ds_model_historical_1hr = xr.open_dataset(f\"{in_dir}Cairns_AUS-15_CMCC-ESM2_historical_r1i1p1f1_BOM_BARPA-R_v1-r1_1hr_1985-2014.nc\").load()\n",
    "# ds_ref_1hr = xr.open_dataset(f\"{root_dir}step1_raw_data_extraction/BARRA-R2/Cairns_AUS-11_ERA5_historical_hres_BOM_BARRA-R2_v1_1hr_1985-2014.nc\").load()\n",
    "\n",
    "# ds_model_historical_1hr[\"lat\"] = ds_ref_1hr[\"lat\"]\n",
    "# ds_model_historical_1hr[\"lon\"] = ds_ref_1hr[\"lon\"]\n",
    "# ds_model_future_1hr[\"lat\"] = ds_ref_1hr[\"lat\"]\n",
    "# ds_model_future_1hr[\"lon\"] = ds_ref_1hr[\"lon\"]\n",
    "# ds_model_future_1hr_aligned = utils.align_future_to_historical(ds_model_historical_1hr, ds_model_future_1hr)\n",
    "\n",
    "# facet_data = []\n",
    "# var_list_1hr = []\n",
    "\n",
    "# for _var in vars_1hr:\n",
    "#     print(f\"===== Var: {_var} =====\")\n",
    "    \n",
    "#     da_obs_1hr = ds_ref_1hr[_var]\n",
    "#     da_model_hist_1hr = ds_model_historical_1hr[_var]\n",
    "#     da_model_fut_1hr = ds_model_future_1hr_aligned[_var]\n",
    "    \n",
    "#     print(da_obs_1hr)\n",
    "#     print(da_model_hist_1hr)\n",
    "#     print(da_model_fut_1hr)\n",
    "    \n",
    "#     _kind = '+' if _var in [\"tas\",\"hurs\", \"clt\", \"uas\", \"vas\"] else '*'\n",
    "                                    \n",
    "#     da_adjusted_1hr, QDC_dict_1hr, adjusted_slices_1hr = utils.apply_hourly_qdc_sliding_window(\n",
    "#         da_obs=da_obs_1hr,\n",
    "#         da_model_historical=da_model_hist_1hr,\n",
    "#         da_model_future=da_model_fut_1hr,\n",
    "#         var=_var,\n",
    "#         kind=_kind,\n",
    "#         window=1\n",
    "#         )\n",
    "                    \n",
    "#     var_list_1hr.append(da_adjusted_1hr.rename(_var).to_dataset())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848a9ade-04be-462a-bd63-30c1a497bf61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T07:19:22.145815Z",
     "iopub.status.busy": "2025-07-21T07:19:22.145350Z",
     "iopub.status.idle": "2025-07-21T07:19:25.554506Z",
     "shell.execute_reply": "2025-07-21T07:19:25.553422Z",
     "shell.execute_reply.started": "2025-07-21T07:19:22.145773Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'argo', 'cfgrib', 'cfradial1', 'datamet', 'era5', 'funwave', 'furuno', 'gamic', 'gini', 'gmt', 'hpl', 'iris', 'json', 'kerchunk', 'metek', 'ncswan', 'ndbc', 'ndbc_ascii', 'netcdf', 'nexradlevel2', 'octopus', 'odim', 'pydap', 'radolan', 'rainbow', 'rasterio', 'spotter', 'swan', 'triaxys', 'wavespectra', 'ww3', 'ww3_station', 'wwm', 'xwaves', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/g/data/eg3/nesp_bff/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m ds_model_future_1hr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mThredbo_AUS-10i_ACCESS-ESM1-5_ssp370_r6i1p1f1_CSIRO_CCAM-v2203-SN_v1-r1_day_2035-2064.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m----> 7\u001b[0m ds_model_historical_1hr \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43min_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mThredbo_AUS-10i_ACCESS-ESM1-5_historical_r6i1p1f1_CSIRO_CCAM-v2203-SN_v1-r1_day_1985-2014\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      8\u001b[0m ds_ref_1hr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mstep1_raw_data_extraction/BARRA-R2/Thredbo_AUS-11_ERA5_historical_hres_BOM_BARRA-R2_v1_day_1985-2014.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     10\u001b[0m ds_model_historical_1hr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ds_ref_1hr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/api.py:668\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 668\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/plugins.py:194\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     )\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'argo', 'cfgrib', 'cfradial1', 'datamet', 'era5', 'funwave', 'furuno', 'gamic', 'gini', 'gmt', 'hpl', 'iris', 'json', 'kerchunk', 'metek', 'ncswan', 'ndbc', 'ndbc_ascii', 'netcdf', 'nexradlevel2', 'octopus', 'odim', 'pydap', 'radolan', 'rainbow', 'rasterio', 'spotter', 'swan', 'triaxys', 'wavespectra', 'ww3', 'ww3_station', 'wwm', 'xwaves', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "vars_1hr = ['rsds','rsdsdir']\n",
    "\n",
    "in_dir = \"/g/data/eg3/nesp_bff/step1_raw_data_extraction/CSIRO-CCAM/\"\n",
    "root_dir = \"/g/data/eg3/nesp_bff/\"\n",
    "\n",
    "ds_model_future_1hr = xr.open_dataset(f\"{in_dir}Thredbo_AUS-10i_ACCESS-ESM1-5_ssp370_r6i1p1f1_CSIRO_CCAM-v2203-SN_v1-r1_day_2035-2064.nc\").load()\n",
    "ds_model_historical_1hr = xr.open_dataset(f\"{in_dir}Thredbo_AUS-10i_ACCESS-ESM1-5_historical_r6i1p1f1_CSIRO_CCAM-v2203-SN_v1-r1_day_1985-2014\").load()\n",
    "ds_ref_1hr = xr.open_dataset(f\"{root_dir}step1_raw_data_extraction/BARRA-R2/Thredbo_AUS-11_ERA5_historical_hres_BOM_BARRA-R2_v1_day_1985-2014.nc\").load()\n",
    "\n",
    "ds_model_historical_1hr[\"lat\"] = ds_ref_1hr[\"lat\"]\n",
    "ds_model_historical_1hr[\"lon\"] = ds_ref_1hr[\"lon\"]\n",
    "ds_model_future_1hr[\"lat\"] = ds_ref_1hr[\"lat\"]\n",
    "ds_model_future_1hr[\"lon\"] = ds_ref_1hr[\"lon\"]\n",
    "ds_model_future_1hr_aligned = utils.align_future_to_historical(ds_model_historical_1hr, ds_model_future_1hr)\n",
    "\n",
    "facet_data = []\n",
    "var_list_1hr = []\n",
    "\n",
    "for _var in vars_1hr:\n",
    "    print(f\"===== Var: {_var} =====\")\n",
    "    \n",
    "    da_obs_1hr = ds_ref_1hr[_var]\n",
    "    da_model_hist_1hr = ds_model_historical_1hr[_var]\n",
    "    da_model_fut_1hr = ds_model_future_1hr_aligned[_var]\n",
    "    \n",
    "    print(da_obs_1hr)\n",
    "    print(da_model_hist_1hr)\n",
    "    print(da_model_fut_1hr)\n",
    "    \n",
    "    _kind = '+' if _var in [\"tasmax\", \"tasmin\"] else '*'\n",
    "\n",
    "    QDC = sdba.QuantileDeltaMapping.train(\n",
    "        da_model_future,\n",
    "        da_model_historical,\n",
    "        nquantiles=100,\n",
    "        group='time.month',\n",
    "        kind=_kind\n",
    "    )\n",
    "\n",
    "    da_ref_adjust = QDC.adjust(da_ref, interp='linear').rename(_var)\n",
    "\n",
    "    def plot_mean(ax, var=_var, da_ref=da_ref, da_model_historical=da_model_historical, da_model_future=da_model_future, da_ref_adjust=da_ref_adjust):\n",
    "        da_ref.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=\"Reference historical (BARRA-R2, 2000)\")\n",
    "        da_model_historical.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=f\"{_rcm}-{_gcm} historical (2000)\")\n",
    "        da_model_future.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=f\"{_rcm}-{_gcm} {_scenario} - future ({_future})\")\n",
    "        da_ref_adjust.groupby(\"time.dayofyear\").mean().plot(ax=ax, label=\"Reference - adjusted - future\", linestyle=\"--\")\n",
    "        ax.set_title(f\"{loc}, {var} - Mean Daily\")\n",
    "        ax.legend()\n",
    "    \n",
    "    facet_data.append(plot_mean)\n",
    "    \n",
    "    def plot_qdc_af(ax, var=_var, qdc=QDC, kind=_kind, cmap_default=cmap_dict.get(_var, \"viridis\")):\n",
    "        af = qdc.ds.af\n",
    "        vmin = float(af.min())\n",
    "        vmax = float(af.max())\n",
    "    \n",
    "        if vmin < 0 and vmax > 0:\n",
    "            cmap = \"RdBu_r\"\n",
    "            center = 0.0\n",
    "        else:\n",
    "            cmap = cmap_default\n",
    "            center = None\n",
    "    \n",
    "        af.transpose(\"month\", \"quantiles\").plot.pcolormesh(\n",
    "            ax=ax, cmap=cmap, center=center,\n",
    "            x=\"quantiles\", y=\"month\",\n",
    "            cbar_kwargs={\"label\": \"Adjustment Factor\"})\n",
    "        ax.set_title(f\"{var} - Adjustment Factors ({kind})\")\n",
    "    \n",
    "    facet_data.append(plot_qdc_af)\n",
    "    \n",
    "    def plot_hist(ax, var=_var, da_ref=da_ref, da_model_historical=da_model_historical, da_model_future=da_model_future, da_ref_adjust=da_ref_adjust):\n",
    "        sns.histplot(da_ref.values.flatten(), ax=ax, label=\"Obs (BARRA-R2)\", kde=True, stat=\"density\", bins=50, color=\"blue\")\n",
    "        sns.histplot(da_model_historical.values.flatten(), ax=ax, label=f\"Hist {_rcm}-{_gcm} {_scenario}\", kde=True, stat=\"density\", bins=50, color=\"green\")\n",
    "        sns.histplot(da_model_future.values.flatten(), ax=ax, label=f\"2050 {_rcm}-{_gcm} {_scenario}\", kde=True, stat=\"density\", bins=50, color=\"red\")\n",
    "        sns.histplot(da_ref_adjust.values.flatten(), ax=ax, label=\"Adjusted\", kde=True, stat=\"density\", bins=50, color=\"purple\")\n",
    "        ax.set_title(f\"{loc}, {var} - Distribution\")\n",
    "        ax.legend()\n",
    "    \n",
    "    facet_data.append(plot_hist)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1528b8-7038-4d5d-b7db-76e64acb1ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-25.06] *",
   "language": "python",
   "name": "conda-env-analysis3-25.06-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
